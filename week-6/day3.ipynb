{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture Plan\n",
    "\n",
    "1. Chains\n",
    "   - Simple Sequenctial Chain\n",
    "   - Sequential Chain\n",
    "   - Router Chain\n",
    "   - Math Chain\n",
    "   - Tranform Chain\n",
    "2. Document Loaders\n",
    "3. Transformers\n",
    "4. Text Embeddings\n",
    "5. Vector Store\n",
    "6. Retreivers\n",
    "7. Multi Query Retreival\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain Expression Language (LCEL)\n",
    "\n",
    "\n",
    "- Easy way to compose chains together using Runnable Interface\n",
    "  \n",
    "Provides:\n",
    "\n",
    "- Streaming\n",
    "- Async\n",
    "- Parallel Execution\n",
    "- Retires and Fallbacks\n",
    "- Input and Output Schemas\n",
    "- Integration with langsmith\n",
    "\n",
    "#### Runnable Interface\n",
    "\n",
    "- strem\n",
    "- invoke\n",
    "- batch\n",
    "\n",
    "Async:\n",
    "\n",
    "- astrem\n",
    "- ainvoke\n",
    "- abatch\n",
    "\n",
    "\n",
    "[LCEL Reference](https://python.langchain.com/docs/expression_language/interface)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnable Interface\n",
    "\n",
    "\n",
    "1. Runnable Parallel: used to define  and run multiple values and operations in parallel.\n",
    "\n",
    "2. Runnble Passthrough: used to take the input and pass it through \n",
    "\n",
    "3. Runnable Lambda: used to turn the python functions to pipe compatable functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\TrainingMaterial\\generative-ai\\genai-material\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models.openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model='gpt-3.5-turbo', temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"You are a code assistant that generates code for users input\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"provide code for {text} in {language}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure! Here\\'s a code snippet that prints all prime numbers within a given range in Python:\\n\\n```python\\ndef is_prime(num):\\n    if num < 2:\\n        return False\\n    for i in range(2, int(num ** 0.5) + 1):\\n        if num % i == 0:\\n            return False\\n    return True\\n\\nstart = int(input(\"Enter the starting number: \"))\\nend = int(input(\"Enter the ending number: \"))\\n\\nprint(\"Prime numbers between\", start, \"and\", end, \"are:\")\\nfor num in range(start, end + 1):\\n    if is_prime(num):\\n        print(num)\\n```\\n\\nIn this code, we define a helper function `is_prime()` that checks whether a number is prime or not. Then, we take user input for the starting and ending numbers of the range. Finally, we iterate through the range and print all the prime numbers within that range.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM Chain\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({'text':'print prime numbers', 'language':'python'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Sequential Chain\n",
    "\n",
    "![Simple Sequential Chain](./images/SimpleSequentialChain.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"You are an assistant that provides company name based on the description provided by the user\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\")\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "slogan_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"genrate a slogan from company name provided by the user\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{company_name}\")\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "chain = RunnableParallel(\n",
    "    company_name = company_name_prompt | model,\n",
    "    company_slogan = {'company_name' : company_name_prompt | model} | slogan_prompt_template | model | parser \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'company_name': AIMessage(content='Enchanted Harvest'),\n",
       " 'company_slogan': '\"Magically Delicious Beans from EnchantaBeans!\"'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'text':'a company that sells magic beans'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential Chain\n",
    "\n",
    "![Sequential Chain](./images/SequentialChain.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Router Chain\n",
    "\n",
    "![Router Chain](./images/RouterChain.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Math Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
