{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture Plan\n",
    "\n",
    "1. AutoGen\n",
    "2. AutoGen Studio\n",
    "3. LangSmith\n",
    "4. other frameworks:\n",
    "  - Flowise\n",
    "  - LangFlow\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain vs AutoGen\n",
    "\n",
    "\n",
    "**LangChain:**\n",
    "\n",
    "1. LLM based applications with Chains, Tools and Agents\n",
    "2. LangChain natievly supports to multiple external data sources\n",
    "3. LangChain uses a Chain Based approach. \n",
    "4. LangChain recently launched LangGraph which supports DAG in Chains and extends LangChain's existing features to Multi Agent workflows.\n",
    "\n",
    "**AutoGen**\n",
    "\n",
    "1. Multi Agent Framework from Microsoft.\n",
    "2. Used to build LLM Applications with workflows involving the Multi Agent Conversations.\n",
    "3. AutoGen uses an Agent Based  Approach\n",
    "4. AutoGen recently launched AutoGen studio. It is a web interface for rapid prototyping.\n",
    "\n",
    "![AutoGen Framework](./images/autogen.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pyautogen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config List\n",
    "\n",
    "- specify the model and other configuration info to agent.\n",
    "\n",
    "**ways to generate config list:**\n",
    "\n",
    "1. `get_config_list`: generates config list for API calls\n",
    "2. `config_list_openai_aoai`:  generates config list for OpenAI and Azure OpenAI endpoints\n",
    "3. `config_list_from_json`: loads configuration from a JSON file. `filter_dict` is used to filter the `config_list_from_json` file.\n",
    "4. `config_list_from_models`: creates configurations based on provided list of models.\n",
    "5. `config_list_from_dotenv`: loads configuration from a .env file. `filter_dict` is used to filter the `config_list_from_json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import config_list_from_dotenv\n",
    "\n",
    "config_list = config_list_from_dotenv(\n",
    "    dotenv_file_path='C:/TrainingMaterial/generative-ai/genai-material/.env',\n",
    "    filter_dict={\n",
    "        \"model\":{\n",
    "            \"gpt-3.5-turbo\"\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agents\n",
    "\n",
    "AutoGen provides an abstraction for creating the agents with following features:\n",
    "\n",
    "- **Conversable:** Any agent can send or recieve messages from the other agent.\n",
    "- **Customizable:** Agents in autogen can be integrated with LLMs, tools and humans.\n",
    "\n",
    "#### Multi Agent Conversational Framework\n",
    "\n",
    "![AutoGen Agents](./images/autogen_agents.png)\n",
    "\n",
    "\n",
    "1. `ConversableAgent`: Genric class for agents that converse with each other by exchnaging messages.\n",
    "2. `AssistantAgent`: designed to act as an AI Assistant using LLMs.\n",
    "3. `UserProxyAgent`: proxy for humans.\n",
    "4. `GroupChatManager` : A chat manager that can manage a group chat of multiple agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser proxy agent\u001b[0m (to assitant):\n",
      "\n",
      "Code to sort the numbers using merge sort\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Missing required arguments; Expected either ('messages' and 'model') or ('messages', 'model' and 'stream') arguments to be given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 37\u001b[0m\n\u001b[0;32m      5\u001b[0m assistant \u001b[38;5;241m=\u001b[39m AssistantAgent(\n\u001b[0;32m      6\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massitant\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     llm_config\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     max_consecutive_auto_reply\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     17\u001b[0m user_proxy \u001b[38;5;241m=\u001b[39m UserProxyAgent(\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser proxy agent\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \n\u001b[0;32m     35\u001b[0m )\n\u001b[1;32m---> 37\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43muser_proxy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43massistant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43mCode to sort the numbers using merge sort\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[0;32m     40\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\TrainingMaterial\\generative-ai\\genai-material\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:698\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[1;34m(self, recipient, clear_history, silent, cache, **context)\u001b[0m\n\u001b[0;32m    696\u001b[0m     agent\u001b[38;5;241m.\u001b[39mclient_cache \u001b[38;5;241m=\u001b[39m cache\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_chat(recipient, clear_history)\n\u001b[1;32m--> 698\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_init_message\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m, recipient]:\n\u001b[0;32m    700\u001b[0m     agent\u001b[38;5;241m.\u001b[39mclient_cache \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mprevious_cache\n",
      "File \u001b[1;32mc:\\TrainingMaterial\\generative-ai\\genai-material\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:441\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    439\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient)\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[1;32m--> 441\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m     )\n",
      "File \u001b[1;32mc:\\TrainingMaterial\\generative-ai\\genai-material\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:599\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 599\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(reply, sender, silent\u001b[38;5;241m=\u001b[39msilent)\n",
      "File \u001b[1;32mc:\\TrainingMaterial\\generative-ai\\genai-material\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1298\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[1;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[1;32m-> 1298\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final:\n\u001b[0;32m   1300\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reply\n",
      "File \u001b[1;32mc:\\TrainingMaterial\\generative-ai\\genai-material\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:813\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m    810\u001b[0m         all_messages\u001b[38;5;241m.\u001b[39mappend(message)\n\u001b[0;32m    812\u001b[0m \u001b[38;5;66;03m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[1;32m--> 813\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_oai_system_message\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mall_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    817\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    819\u001b[0m extracted_response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mextract_text_or_completion_object(response)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    821\u001b[0m \u001b[38;5;66;03m# ensure function and tool calls will be accepted when sent back to the LLM\u001b[39;00m\n",
      "File \u001b[1;32mc:\\TrainingMaterial\\generative-ai\\genai-material\\.venv\\Lib\\site-packages\\autogen\\oai\\client.py:283\u001b[0m, in \u001b[0;36mOpenAIWrapper.create\u001b[1;34m(self, **config)\u001b[0m\n\u001b[0;32m    281\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# filter is not passed; try the next config\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 283\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_completions_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m APIError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    285\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(err, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\TrainingMaterial\\generative-ai\\genai-material\\.venv\\Lib\\site-packages\\autogen\\oai\\client.py:548\u001b[0m, in \u001b[0;36mOpenAIWrapper._completions_create\u001b[1;34m(self, client, params)\u001b[0m\n\u001b[0;32m    546\u001b[0m     params \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    547\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 548\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\TrainingMaterial\\generative-ai\\genai-material\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:270\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: Missing required arguments; Expected either ('messages' and 'model') or ('messages', 'model' and 'stream') arguments to be given"
     ]
    }
   ],
   "source": [
    "# Code generation agent\n",
    "\n",
    "from autogen import AssistantAgent, UserProxyAgent\n",
    "\n",
    "assistant = AssistantAgent(\n",
    "    name = \"assitant\",\n",
    "    llm_config={\n",
    "        \"config_agent\": config_list,\n",
    "        \"temperature\": 0.0,\n",
    "        \"cache_seed\": 42\n",
    "\n",
    "    },\n",
    "    max_consecutive_auto_reply= 10\n",
    ")\n",
    "\n",
    "\n",
    "user_proxy = UserProxyAgent(\n",
    "\n",
    "    name = \"user proxy agent\",\n",
    "    llm_config={\n",
    "        \"config_agent\": config_list,\n",
    "        \"temperature\": 0.0,\n",
    "        \"cache_seed\": 42\n",
    "\n",
    "    },\n",
    "    system_message=\"reply TERMINATE when you are done with the code\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"C:/TrainingMaterial/generative-ai/genai-material/trng-1855/trng-git-repo/trng-1855/week-7/\",\n",
    "        \"use_docker\" : False\n",
    "    },\n",
    "    is_termination_msg = lambda x : x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    max_consecutive_auto_reply= 10\n",
    "    \n",
    ")\n",
    "\n",
    "response = user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message = \"\"\"Code to sort the numbers using merge sort\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent Group Chat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "\n",
    "\n",
    "- [AutoGen Docs](https://microsoft.github.io/autogen/docs/Getting-Started)\n",
    "- [AutoGen SDK](https://microsoft.github.io/autogen/docs/reference/agentchat/conversable_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoGen Studio\n",
    "\n",
    "- An inteface by AutoGen used to rapildly create agents and multi agent workflows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install autogenstudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`autogenstudio ui --port 8081`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
