{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Ops & MLOps workflow\n",
    "\n",
    "Platform for custom ML model development & deployment with MLOps tools.\n",
    "\n",
    "\n",
    "ML workflow:\n",
    "\n",
    "1. Ingest \n",
    "2. Analyze\n",
    "3. Transform\n",
    "4. Train\n",
    "5. Model\n",
    "6. Evaluate\n",
    "7. Deploy\n",
    "8. Predict\n",
    "\n",
    "- 1 to 3: data preperation. done using managed datasets in vertexAI. lable and annotate the data.\n",
    "- train- AutoML and custom. img, vid, text and tabular - automl is suitable. custom model- tensorflow and pytorch.\n",
    "- Evaluate: explainable AI, evaluate the model and dive deeper into the model and understand it better.\n",
    "- deploy: deploy it to an endpoint(scalable). \n",
    "-  undeployed for batch predictions. deployed model prediction - CLI, UI, SDK and APIs\n",
    "\n",
    "\n",
    "Even after models are deployed, they are trained frequently using new datasets so, thay can stay relevent.\n",
    "\n",
    "ML Workflows are automated using Vertex AI Pipelines\n",
    "\n",
    "\n",
    "#### Training Steps & Iterations\n",
    "\n",
    "\n",
    "**Epoch:** The process of training the model once with the entire dataset.\n",
    "\n",
    "**Batch:** The entire dataset can not be passed for training at once. So, the datset is divided into parts called batches.\n",
    "\n",
    "**Iteration:** No of training examples divided by the batch size gives the value of no of iterations.\n",
    "\n",
    "#### Model Versioning\n",
    "\n",
    "- Model versioning helps you to create multiple versions of the same model. It helps to track the changes and performance metrics of the model. \n",
    "- The initial version is 1 and it increates with  each update or retraining of the model.\n",
    "\n",
    "#### Feature Engineering\n",
    "\n",
    "- The process of creating new features(columns), tramsforming existing ones and selecting the most relevent features to train and imporve the performance of the model.\n",
    "- In vertex AI feature engineering is implemneted using the Vertex AI Feature store and feature transform engine.\n",
    "- If feature selection is enabled, Feature Transform Engine assigns an importance score to each feature.\n",
    "\n",
    "#### Hyperparameters and Hyper paramater tuning\n",
    "\n",
    "- Hyperparameters are the variables that control the model training. They are not related to the actual data used for the training.\n",
    "\n",
    "ex:\n",
    "\n",
    "1. No of nodes and layers in Neural network\n",
    "2. Model architecture\n",
    "3. Learning rate\n",
    "\n",
    "# LLMOps\n",
    "\n",
    "- Extension of MLOps. Automation of dataprep, train, evaluate, deploy the LLM applications.\n",
    "\n",
    "### MLOps\n",
    "\n",
    "- ML engineering culture and practice of combining ML Dev and ML Ops\n",
    "\n",
    "Automation & Monitoring all steps in ML system construction\n",
    "\n",
    "- train\n",
    "- integrate\n",
    "- test\n",
    "- release\n",
    "- deploy\n",
    "- infra management or monitoring\n",
    "\n",
    "### MLOps Framework or workflow\n",
    "\n",
    "- Data Ingestion --> Data Validation --> Data Tranformation --> Model training or tuning --> Test or analysis --> Deploy --> Monitoring\n",
    "\n",
    "Automation and Orchestration\n",
    "\n",
    "- Automate the process and specify the steps to achive the output.\n",
    "- 1D process\n",
    "\n",
    "### MLOps for LLM\n",
    "\n",
    "- Focus on LLM developent and monitoring\n",
    "- experimentation on foundational models\n",
    "- Prompt design and management\n",
    "- supervised tuning\n",
    "- monitoring\n",
    "- evaluate generated output\n",
    "\n",
    "### LLM System Design\n",
    "\n",
    "- Design of E2E application\n",
    "- LLM Chaining\n",
    "- Grounding (additional info to LLM)\n",
    "- Tracking history\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
