{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture Plan\n",
    "\n",
    "1. AI, ML and Gen AI Introduction\n",
    "2. LLMs\n",
    "3. Hugging face\n",
    "   - Huggingface models\n",
    "   - pipelines and finetuning\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Intelligence\n",
    "\n",
    "Development of computer systems to perform tasks that require human Intelligence. Logical resoning, NLP, Problem solving. \n",
    "\n",
    "### Machine Learning\n",
    "\n",
    "- Subset of AI focusing on developing models that enable computers to learn from data without explicit programming.\n",
    "- ML Model:\n",
    "  - data prep\n",
    "  - train\n",
    "  - evaluate\n",
    "- The models performce is directly proportinal to the quality of training data and duration of training.\n",
    "\n",
    "f(x) = wx+ b\n",
    "\n",
    "Types of learning:\n",
    "\n",
    "- Supervised Learning\n",
    "- Unsupervised Learning\n",
    "  - Self Supervised Learning \n",
    "- Semi Supervised Learning\n",
    "\n",
    "### Generative AI\n",
    "\n",
    "Gen AI, generates text, images, videos, code, speech and other media.\n",
    "\n",
    "### LLM\n",
    "\n",
    "- LLMs are Langauge models that are trained to generate the next words or tokens, given some input text.\n",
    "- Natural Language Processing (NLP): Natural Language Underatanding (NLU) + Natural Lnaguage Generation (NLG) \n",
    "\n",
    "#### Examples\n",
    "\n",
    "- Open AI: GPT 2, 3, 3.5 turbo 4.\n",
    "- Antropic: Claude 1, 2\n",
    "- Google: PaLM text-bision, chat-bision\n",
    "- Meta: LLama, LLama 2\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face\n",
    "\n",
    "- Open source data science and Machine learning platform. It started as a chatbot for teenagers in 2017.\n",
    "- It is used to build, train and deploy the AI models.\n",
    "\n",
    "### transformers library\n",
    "\n",
    "It is a python library maintained by hugging face for Machine Learning for Pytorch, Tensorflow and JAX. Provides thousands (25k) of pretrained models to perform tasks on various forms of data like text, vision, audio.\n",
    "\n",
    "\n",
    "### pipeline\n",
    "\n",
    "pipleines are easy to use interfces for models. they abstract most of the complex code from library, offering a simple API to perform taks luke Sentiment analysus, named entity recognition (a natural language processing (NLP) technique that identifies and categorizes information in text), masked language modeling(to predict missing words in a sentence).\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "- Extracting the answer from a context (question-answering).\n",
    "- Creating summaries from a large text (summarization).\n",
    "- Classify text (e.g. as spam or not spam, text-classification).\n",
    "- Generate a new text with models such as GPT (text-generation).\n",
    "- Identify parts of speech (verb, subject, etc.) or entities (country, organization, etc.) in a sentence (token-classification).\n",
    "- Transcribe audio files to text (automatic-speech-recognition).\n",
    "- Classify the speaker or language in an audio file (audio-classification).\n",
    "- Detect objects in an image (object-detection).\n",
    "- Segment an image (image-segmentation).\n",
    "- Reinforcement Learning (reinforcement-learning)\n",
    "\n",
    "\n",
    "Internally the pipeline does three things:\n",
    "\n",
    "1. Preprocessing the text using a tokenizer\n",
    "2. Feeds the preprocessed text to the model\n",
    "3. Post processing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tensorflow transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\TrainingMaterial\\generative-ai\\genai-material\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9661751389503479}]\n"
     ]
    }
   ],
   "source": [
    "print(classifier(\"I am exicte to learn gen Ai!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'Mt Everest is the tallest mountain the world',\n",
       " 'labels': ['Geographical', 'General', 'Political'],\n",
       " 'scores': [0.7967474460601807, 0.15498808026313782, 0.04826448857784271]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", candidate_labels=[\"Geographical\", \"Political\", \"General\"])\n",
    "\n",
    "classifier(\"Mt Everest is the tallest mountain the world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9993606209754944}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n",
    "\n",
    "\n",
    "classifier = pipeline('sentiment-analysis', model = model, tokenizer= tokenizer)\n",
    "\n",
    "\n",
    "classifier(\"Hey!\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1045, 2572, 4083, 8991, 9932, 1010, 1045, 102]\n"
     ]
    }
   ],
   "source": [
    "enc_text = tokenizer.encode(\"I am learning Gen AI\")\n",
    "\n",
    "print(enc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] i am learning gen ai [SEP]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(enc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
